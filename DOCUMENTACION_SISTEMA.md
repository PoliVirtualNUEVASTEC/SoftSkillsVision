# ğŸ“Š DocumentaciÃ³n Completa del Sistema SoftSkillsVision

## ğŸ¯ Resumen Ejecutivo

**SoftSkillsVision** es un sistema ATS (Applicant Tracking System) que utiliza inteligencia artificial para evaluar las habilidades blandas (soft skills) de candidatos mediante el anÃ¡lisis de videos de entrevistas. El sistema detecta 7 emociones bÃ¡sicas y determina si un candidato posee las competencias emocionales requeridas para un puesto especÃ­fico.

---

## ğŸ—ï¸ Arquitectura del Sistema

### Componentes Principales

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SoftSkillsVision                        â”‚
â”‚                  Sistema ATS con IA                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         â”‚         â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚           â”‚ â”‚       â”‚ â”‚            â”‚
            â”‚ SoftSkillsâ”‚ â”‚SoftSkillsâ”‚ â”‚SoftSkills  â”‚
            â”‚  Vision   â”‚ â”‚ Vision â”‚ â”‚ Vision     â”‚
            â”‚  (Python) â”‚ â”‚ Front  â”‚ â”‚ BackEnd    â”‚
            â”‚           â”‚ â”‚(Angular)â”‚ â”‚ (Spring)   â”‚
            â”‚   IA &    â”‚ â”‚        â”‚ â”‚            â”‚
            â”‚ Business  â”‚ â”‚   UI   â”‚ â”‚ Database   â”‚
            â”‚  Logic    â”‚ â”‚        â”‚ â”‚ Connection â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1. **Backend Python (IA & Business Logic)**
- **Framework**: FastAPI
- **IA**: MediaPipe + FER (Facial Emotion Recognition)
- **Procesamiento**: OpenCV + TensorFlow
- **Almacenamiento**: Google Drive API

### 2. **Frontend Angular**
- **Framework**: Angular 19
- **UI**: Bootstrap 5 + ngx-bootstrap
- **Lenguaje**: TypeScript

### 3. **Backend Java**
- **Framework**: Spring Boot 3.4.4
- **Base de Datos**: SQL Server
- **ORM**: Spring Data JPA

---

## ğŸ”„ Diagrama de Flujo del Proceso Principal

```mermaid
flowchart TD
    A[ğŸ¥ Video de Entrevista] --> B{ğŸ“ Fuente del Video}
    B -->|Local| C[ğŸ“‚ Video Local]
    B -->|Google Drive| D[â˜ï¸ Google Drive API]
    
    C --> E[ğŸ” Validar Archivo]
    D --> F[ğŸ“¥ Descargar Video]
    F --> E
    
    E --> G{âœ… Archivo VÃ¡lido?}
    G -->|No| H[âŒ Error: Archivo no vÃ¡lido]
    G -->|SÃ­| I[ğŸ¬ Inicializar VideoCapture]
    
    I --> J[ğŸ¤– Inicializar Detectores]
    J --> K[ğŸ“Š MediaPipe Face Landmarker]
    J --> L[ğŸ˜Š FER Emotion Detector]
    
    K --> M[ğŸ”„ Procesar Frame por Frame]
    L --> M
    
    M --> N[ğŸ¨ Convertir BGR a RGB]
    N --> O[ğŸ‘¤ Detectar Landmarks Faciales]
    O --> P[ğŸ˜Š Detectar EmociÃ³n]
    P --> Q[ğŸ“ Anotar Frame]
    Q --> R[ğŸ–¼ï¸ Mostrar Video Procesado]
    
    R --> S{ğŸ”„ MÃ¡s Frames?}
    S -->|SÃ­| M
    S -->|No| T[ğŸ“Š Calcular Promedios]
    
    T --> U[ğŸ§® Agrupar Emociones por Tipo]
    U --> V[ğŸ“ˆ Calcular Scores Promedio]
    V --> W[ğŸ“‹ Generar Resultado JSON]
    W --> X[ğŸ’¾ Almacenar Resultados]
    X --> Y[ğŸ¯ Evaluar Soft Skills]
    Y --> Z[âœ… Resultado Final]
    
    H --> END[ğŸ Fin del Proceso]
    Z --> END
```

---

## ğŸ­ Proceso de DetecciÃ³n de Emociones

### Emociones Detectadas
1. **Neutro** - Estado neutral
2. **Feliz** - AlegrÃ­a y satisfacciÃ³n
3. **Triste** - MelancolÃ­a y pena
4. **Enfadado** - Ira y frustraciÃ³n
5. **Miedo** - Ansiedad y preocupaciÃ³n
6. **Desagrado** - RepulsiÃ³n y disgusto
7. **Sorpresa** - Asombro e incredulidad

### Algoritmo de Procesamiento

```mermaid
flowchart LR
    A[ğŸ¬ Frame del Video] --> B[ğŸ¨ ConversiÃ³n BGRâ†’RGB]
    B --> C[ğŸ‘¤ MediaPipe Landmarks]
    B --> D[ğŸ˜Š FER Emotion Detection]
    
    C --> E[ğŸ“ 468 Puntos Faciales]
    D --> F[ğŸ¯ Top Emotion + Score]
    
    E --> G[ğŸ¨ Dibujar Malla Facial]
    F --> H[ğŸ“ Anotar EmociÃ³n]
    
    G --> I[ğŸ–¼ï¸ Frame Anotado]
    H --> I
    
    I --> J[ğŸ“Š Acumular Datos]
    J --> K[ğŸ”„ Siguiente Frame]
```

---

## ğŸ›ï¸ Diagrama de Clases

### Backend Python

```mermaid
classDiagram
    class FastAPI {
        +app: FastAPI
        +include_router()
    }
    
    class APIRouter {
        +router: APIRouter
        +process_video_endpoint()
        +analyze_emotions_from_drive()
    }
    
    class EmotionResult {
        +emotion: str
        +score: float
    }
    
    class FaceVideoRecog {
        +emotions_dict: dict
        +draw_landmarks_on_image()
        +process_video()
        +get_files_from_drive()
    }
    
    class DriveUtils {
        +download_video_from_drive()
        +get_video_info_from_drive()
    }
    
    class MediaPipeDetector {
        +base_options: BaseOptions
        +options: FaceLandmarkerOptions
        +detector: FaceLandmarker
        +detect()
    }
    
    class FERDetector {
        +emotion_detector: FER
        +top_emotion()
    }
    
    FastAPI --> APIRouter
    APIRouter --> EmotionResult
    APIRouter --> FaceVideoRecog
    FaceVideoRecog --> MediaPipeDetector
    FaceVideoRecog --> FERDetector
    APIRouter --> DriveUtils
```

### Frontend Angular

```mermaid
classDiagram
    class AppComponent {
        +title: string
    }
    
    class Candidato {
        +id: number
        +nombre: string
        +email: string
        +videoUrl: string
    }
    
    class Cargo {
        +id: number
        +nombre: string
        +descripcion: string
        +requisitos: string
    }
    
    class Emocion {
        +id: number
        +nombre: string
        +descripcion: string
    }
    
    class Habilidad {
        +id: number
        +nombre: string
        +descripcion: string
        +emociones: Emocion[]
    }
    
    class PuntuacionEmociones {
        +candidatoId: number
        +emocionId: number
        +puntuacion: number
        +timestamp: Date
    }
    
    class CandidatoService {
        +getCandidatos()
        +createCandidato()
        +updateCandidato()
        +deleteCandidato()
    }
    
    class FaceLandMakerService {
        +procesarVideo()
        +analizarEmociones()
    }
    
    AppComponent --> CandidatoService
    CandidatoService --> Candidato
    Candidato --> PuntuacionEmociones
    PuntuacionEmociones --> Emocion
    Habilidad --> Emocion
    FaceLandMakerService --> PuntuacionEmociones
```

---

## ğŸ¯ Casos de Uso

### CU-001: Procesar Video de Entrevista

**Actor Principal**: Reclutador
**Precondiciones**: 
- El sistema estÃ¡ funcionando
- El video estÃ¡ disponible (local o en Google Drive)

**Flujo Principal**:
1. El reclutador selecciona un video de entrevista
2. El sistema valida el archivo de video
3. El sistema procesa el video frame por frame
4. Para cada frame:
   - Detecta landmarks faciales con MediaPipe
   - Detecta emociones con FER
   - Anota el frame con la informaciÃ³n
5. El sistema calcula promedios de emociones
6. El sistema genera un reporte de emociones
7. El sistema evalÃºa las soft skills del candidato
8. El sistema presenta los resultados al reclutador

**Flujos Alternativos**:
- **3a**: Si el video no es vÃ¡lido, mostrar error
- **4a**: Si no se detecta cara, continuar con el siguiente frame
- **5a**: Si no hay suficientes datos, solicitar video mÃ¡s largo

**Postcondiciones**:
- Se genera un reporte de emociones
- Se evalÃºan las soft skills del candidato
- Los resultados se almacenan en la base de datos

### CU-002: Analizar Videos desde Google Drive

**Actor Principal**: Reclutador
**Precondiciones**:
- Credenciales de Google Drive configuradas
- Acceso a la carpeta de videos

**Flujo Principal**:
1. El reclutador especifica el ID de la carpeta de Google Drive
2. El sistema se conecta a Google Drive API
3. El sistema lista todos los videos en la carpeta
4. Para cada video:
   - Descarga el video temporalmente
   - Procesa el video (CU-001)
   - Elimina el archivo temporal
5. El sistema genera un reporte consolidado
6. El sistema presenta los resultados al reclutador

### CU-003: Gestionar Candidatos

**Actor Principal**: Reclutador
**Precondiciones**: Usuario autenticado

**Flujo Principal**:
1. El reclutador accede a la lista de candidatos
2. El sistema muestra la lista de candidatos
3. El reclutador puede:
   - Ver detalles de un candidato
   - Editar informaciÃ³n del candidato
   - Ver resultados de evaluaciÃ³n
   - Eliminar candidato
4. El sistema actualiza la informaciÃ³n segÃºn la acciÃ³n

### CU-004: Configurar Rangos de Emociones por Cargo

**Actor Principal**: Administrador
**Precondiciones**: Usuario con permisos de administrador

**Flujo Principal**:
1. El administrador selecciona un cargo
2. El sistema muestra los rangos actuales de emociones
3. El administrador modifica los rangos segÃºn los requisitos del cargo
4. El sistema valida los rangos
5. El sistema guarda la configuraciÃ³n
6. El sistema confirma la actualizaciÃ³n

---

## ğŸ‘¥ Historias de Usuario

### Epic 1: Procesamiento de Videos

#### HU-001: Como reclutador, quiero procesar un video de entrevista para evaluar las emociones del candidato
**Criterios de AceptaciÃ³n**:
- âœ… Puedo cargar un video desde mi computadora
- âœ… Puedo especificar un video desde Google Drive
- âœ… El sistema detecta 7 emociones bÃ¡sicas
- âœ… Recibo un reporte con puntuaciones de emociones
- âœ… El procesamiento toma menos de 5 minutos para un video de 10 minutos

**DefiniciÃ³n de Terminado**:
- [ ] Video se procesa correctamente
- [ ] Emociones se detectan con precisiÃ³n >80%
- [ ] Reporte se genera en formato JSON
- [ ] Interfaz muestra progreso del procesamiento

#### HU-002: Como reclutador, quiero procesar mÃºltiples videos de una carpeta de Google Drive
**Criterios de AceptaciÃ³n**:
- âœ… Puedo especificar el ID de una carpeta de Google Drive
- âœ… El sistema procesa todos los videos de la carpeta
- âœ… Recibo un reporte consolidado por video
- âœ… Los videos se procesan en paralelo cuando es posible

### Epic 2: GestiÃ³n de Candidatos

#### HU-003: Como reclutador, quiero registrar un nuevo candidato
**Criterios de AceptaciÃ³n**:
- âœ… Puedo ingresar nombre, email y informaciÃ³n bÃ¡sica
- âœ… Puedo asociar un video de entrevista
- âœ… El sistema valida que el email sea Ãºnico
- âœ… Recibo confirmaciÃ³n del registro

#### HU-004: Como reclutador, quiero ver la lista de candidatos con sus evaluaciones
**Criterios de AceptaciÃ³n**:
- âœ… Veo una tabla con todos los candidatos
- âœ… Puedo filtrar por nombre, email o cargo
- âœ… Veo las puntuaciones de emociones de cada candidato
- âœ… Puedo ordenar por diferentes criterios

### Epic 3: EvaluaciÃ³n de Soft Skills

#### HU-005: Como reclutador, quiero evaluar si un candidato tiene las soft skills requeridas para un cargo
**Criterios de AceptaciÃ³n**:
- âœ… Puedo seleccionar un candidato y un cargo
- âœ… El sistema compara las emociones del candidato con los requisitos del cargo
- âœ… Recibo una evaluaciÃ³n clara (Apto/No Apto)
- âœ… Veo un desglose de por quÃ© el candidato es apto o no

#### HU-006: Como administrador, quiero configurar los rangos de emociones ideales para cada cargo
**Criterios de AceptaciÃ³n**:
- âœ… Puedo seleccionar un cargo
- âœ… Puedo establecer rangos mÃ­nimos y mÃ¡ximos para cada emociÃ³n
- âœ… El sistema valida que los rangos sean lÃ³gicos
- âœ… Los cambios se aplican inmediatamente

### Epic 4: Reportes y AnÃ¡lisis

#### HU-007: Como reclutador, quiero generar reportes de evaluaciÃ³n de candidatos
**Criterios de AceptaciÃ³n**:
- âœ… Puedo filtrar candidatos por diferentes criterios
- âœ… Puedo exportar reportes en PDF o Excel
- âœ… Los reportes incluyen grÃ¡ficos de emociones
- âœ… Puedo comparar mÃºltiples candidatos

#### HU-008: Como administrador, quiero ver estadÃ­sticas generales del sistema
**Criterios de AceptaciÃ³n**:
- âœ… Veo nÃºmero total de candidatos evaluados
- âœ… Veo distribuciÃ³n de emociones por cargo
- âœ… Veo tendencias temporales
- âœ… Puedo exportar estadÃ­sticas

---

## ğŸ”§ TecnologÃ­as y Dependencias

### Backend Python
```python
# Framework API
fastapi==0.104.1
uvicorn[standard]==0.24.0

# Procesamiento de imÃ¡genes y video
opencv-python==4.8.1.78
opencv-contrib-python==4.8.1.78
numpy==1.24.3
mediapipe==0.10.7

# Machine Learning / Deep Learning
tensorflow==2.13.0
fer==22.5.1  # Reconocimiento de emociones

# ManipulaciÃ³n multimedia
ffmpeg-python==0.2.0
moviepy==1.0.3

# Google API
google-api-python-client==2.108.0
google-auth==2.23.4
google-auth-oauthlib==1.1.0
gdown==4.7.1

# Validaciones y modelos
pydantic==2.5.0
```

### Frontend Angular
```json
{
  "dependencies": {
    "@angular/animations": "^19.0.0",
    "@angular/common": "^19.0.0",
    "@angular/compiler": "^19.0.0",
    "@angular/core": "^19.0.0",
    "@angular/forms": "^19.0.0",
    "@angular/platform-browser": "^19.0.0",
    "@angular/platform-browser-dynamic": "^19.0.0",
    "@angular/router": "^19.0.0",
    "bootstrap": "^5.3.2",
    "ngx-bootstrap": "^12.0.0",
    "rxjs": "~7.8.0",
    "tslib": "^2.3.0",
    "zone.js": "~0.14.0"
  }
}
```

### Backend Java
```xml
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
        <version>3.4.4</version>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-data-jpa</artifactId>
        <version>3.4.4</version>
    </dependency>
    <dependency>
        <groupId>com.microsoft.sqlserver</groupId>
        <artifactId>mssql-jdbc</artifactId>
        <version>12.4.2.jre11</version>
    </dependency>
</dependencies>
```

---

## ğŸ“Š MÃ©tricas y KPIs

### MÃ©tricas TÃ©cnicas
- **PrecisiÃ³n de detecciÃ³n de emociones**: >80%
- **Tiempo de procesamiento**: <5 min para video de 10 min
- **Disponibilidad del sistema**: >99%
- **Tiempo de respuesta API**: <2 segundos

### MÃ©tricas de Negocio
- **Candidatos evaluados por dÃ­a**: 50+
- **Tiempo promedio de evaluaciÃ³n**: 3 minutos
- **Tasa de precisiÃ³n en selecciÃ³n**: >85%
- **SatisfacciÃ³n del usuario**: >4.5/5

---

## ğŸš€ Instrucciones de Despliegue

### 1. Backend Python
```bash
cd SoftSkillsVision
python -m venv venv
venv\Scripts\activate  # Windows
pip install -r requirements.txt
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 2. Frontend Angular
```bash
cd SoftSkillsVisionFront
npm install
ng serve
```

### 3. Backend Java
```bash
cd SoftSkillsVisionBackEnd
mvn clean compile
mvn spring-boot:run
```

---

## ğŸ” Consideraciones de Seguridad

1. **AutenticaciÃ³n**: Implementar JWT para APIs
2. **AutorizaciÃ³n**: Control de acceso basado en roles
3. **Datos sensibles**: Encriptar videos y resultados
4. **API Keys**: Rotar credenciales periÃ³dicamente
5. **Logs**: AuditorÃ­a de accesos y operaciones

---

## ğŸ“ˆ Roadmap Futuro

### Fase 1 (Actual)
- âœ… Procesamiento bÃ¡sico de videos
- âœ… DetecciÃ³n de 7 emociones
- âœ… IntegraciÃ³n con Google Drive
- âœ… Interfaz web bÃ¡sica

### Fase 2 (PrÃ³ximos 3 meses)
- ğŸ”„ AnÃ¡lisis de voz y tono
- ğŸ”„ DetecciÃ³n de micro-expresiones
- ğŸ”„ Machine Learning personalizado
- ğŸ”„ Reportes avanzados

### Fase 3 (6 meses)
- ğŸ”„ IntegraciÃ³n con LinkedIn
- ğŸ”„ AnÃ¡lisis predictivo
- ğŸ”„ API pÃºblica
- ğŸ”„ Mobile app

---

## ğŸ“ Soporte y Contacto

- **DocumentaciÃ³n**: [GitHub Wiki](https://github.com/usuario/SoftSkillsVision/wiki)
- **Issues**: [GitHub Issues](https://github.com/usuario/SoftSkillsVision/issues)
- **Email**: soporte@softskillsvision.com
- **VersiÃ³n**: 0.0.1-SNAPSHOT

---

*Esta documentaciÃ³n se actualiza regularmente. Ãšltima actualizaciÃ³n: Septiembre 2025*
